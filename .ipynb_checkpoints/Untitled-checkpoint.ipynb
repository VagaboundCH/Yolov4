{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from util.ipynb\n",
      "torch.Size([2, 4])\n",
      "torch.Size([1, 2, 4])\n",
      "torch.Size([2, 1, 4])\n",
      "torch.Size([2, 4, 1])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/User/Yolov4/weights/yolov3.weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7b27aca57280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/User/Yolov4/cfg/yolov3.cfg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/User/Yolov4/weights/yolov3.weights\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Network loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-7b27aca57280>\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, weightfile)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweightfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweightfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;31m#The first 4 values are header information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/User/Yolov4/weights/yolov3.weights'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import import_ipynb\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import cv2 \n",
    "from util import *\n",
    "\n",
    "\n",
    "\n",
    "class dummyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dummyLayer, self).__init__()\n",
    "        \n",
    "\n",
    "class detector(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super(detector, self).__init__()\n",
    "        self.anchors = anchors\n",
    "\n",
    "\n",
    "def construct_cfg(configFile):\n",
    "    '''\n",
    "    Build the network blocks using the configuration file.\n",
    "    Pre-process it to form easy to manupulate using pytorch.\n",
    "    ''' \n",
    "    \n",
    "    # Read and pre-process the configuration file\n",
    "    \n",
    "    config = open(configFile,'r')\n",
    "    file = config.read().split('\\n')\n",
    "    \n",
    "    file = [line for line in file if len(line) > 0 and line[0]!= '#']\n",
    "    file = [line.lstrip().rstrip() for line in file]\n",
    "    \n",
    "    \n",
    "    #Separate network blocks in a list \n",
    "    \n",
    "    networkBlocks = [] \n",
    "    networkBlock = {}\n",
    "\n",
    "    for x in file:\n",
    "        if x[0] == '[':\n",
    "            if len(networkBlock) != 0:\n",
    "                networkBlocks.append(networkBlock)\n",
    "                networkBlock = {}\n",
    "            networkBlock[\"type\"] = x[1:-1].rstrip()\n",
    "        else:\n",
    "            entity , value = x.split('=')\n",
    "            networkBlock[entity.rstrip()] = value.lstrip()\n",
    "    networkBlocks.append(networkBlock)\n",
    "    \n",
    "    return networkBlocks\n",
    "    \n",
    "\n",
    "def buildNetwork(networkBlocks):\n",
    "    DNInfo = networkBlocks[0]\n",
    "    modules = nn.ModuleList([])\n",
    "    channels = 3\n",
    "    filterTracker = [] \n",
    "\n",
    "    for i,x in enumerate(networkBlocks[1:]):\n",
    "        seqModule  = nn.Sequential()\n",
    "        if (x[\"type\"] == \"convolutional\"):\n",
    "\n",
    "            filters= int(x[\"filters\"])\n",
    "            pad = int(x[\"pad\"])\n",
    "            kernelSize = int(x[\"size\"])\n",
    "            stride = int(x[\"stride\"])\n",
    "\n",
    "            if pad:\n",
    "                padding = (kernelSize - 1) // 2\n",
    "            else:\n",
    "                padding = 0\n",
    "            \n",
    "            activation = x[\"activation\"]\n",
    "            try:\n",
    "                bn = int(x[\"batch_normalize\"])\n",
    "                bias = False\n",
    "            except:\n",
    "                bn = 0\n",
    "                bias = True\n",
    "\n",
    "            conv = nn.Conv2d(channels, filters, kernelSize, stride, padding, bias = bias)\n",
    "            seqModule.add_module(\"conv_{0}\".format(i), conv)\n",
    "\n",
    "            if bn:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                seqModule.add_module(\"batch_norm_{0}\".format(i), bn)\n",
    "\n",
    "            if activation == \"leaky\":\n",
    "                activn = nn.LeakyReLU(0.1, inplace = True)\n",
    "                seqModule.add_module(\"leaky_{0}\".format(i), activn)\n",
    "\n",
    "\n",
    "        elif (x[\"type\"] == \"upsample\"):\n",
    "            upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n",
    "            seqModule.add_module(\"upsample_{}\".format(i), upsample)\n",
    "        \n",
    "        elif (x[\"type\"] == \"route\"):\n",
    "            x['layers'] = x[\"layers\"].split(',')\n",
    "            start = int(x['layers'][0])\n",
    "            try:\n",
    "                end = int(x['layers'][1])\n",
    "            except:\n",
    "                end =0\n",
    "            \n",
    "            if start > 0:\n",
    "                start = start - i \n",
    "            if end > 0:\n",
    "                end = end - i\n",
    "            \n",
    "            route = dummyLayer()\n",
    "            seqModule.add_module(\"route_{0}\".format(i),route)\n",
    "            if end < 0:\n",
    "                filters = filterTracker[i+start] + filterTracker[i+end]\n",
    "            else:\n",
    "                filters = filterTracker[i+start]\n",
    "        elif (x[\"type\"] == \"shortcut\"):\n",
    "            shortcut = dummyLayer()\n",
    "            seqModule.add_module(\"shortcut_{0}\".format(i),shortcut)\n",
    "        elif (x[\"type\"] == \"yolo\"):\n",
    "            anchors = x[\"anchors\"].split(',')\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            masks = x[\"mask\"].split(',')\n",
    "            masks = [int(a) for a in masks]\n",
    "            anchors = [(anchors[j],anchors[j+1]) for j in range(0,len(anchors),2)]\n",
    "            anchors = [anchors[j] for j in masks]\n",
    "            detectorLayer = detector(anchors)\n",
    "\n",
    "            seqModule.add_module(\"Detection_{0}\".format(i),detectorLayer)\n",
    "        \n",
    "        modules.append(seqModule)\n",
    "        channels = filters\n",
    "        filterTracker.append(filters)\n",
    "    return (DNInfo, modules)\n",
    "\n",
    "\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self, cfgfile):\n",
    "        super(net, self).__init__()\n",
    "        self.netBlocks = construct_cfg(cfgfile)\n",
    "        self.DNInfo, self.moduleList = buildNetwork(self.netBlocks)\n",
    "        self.header = torch.IntTensor([0,0,0,0])\n",
    "        self.seen = 0\n",
    "                \n",
    "    def forward(self, x, CUDA):\n",
    "        detections = []\n",
    "        modules = self.netBlocks[1:]\n",
    "        layerOutputs = {}  \n",
    "        \n",
    "        \n",
    "        written_output = 0\n",
    "        #Iterate throught each module \n",
    "        for i in range(len(modules)):        \n",
    "            \n",
    "            module_type = (modules[i][\"type\"])\n",
    "            #Upsampling is basically a form of convolution\n",
    "            if module_type == \"convolutional\" or module_type == \"upsample\" :\n",
    "                \n",
    "                x = self.moduleList[i](x)\n",
    "                layerOutputs[i] = x\n",
    "\n",
    "            #Add outouts from previous layers to this layer\n",
    "            elif module_type == \"route\":\n",
    "                layers = modules[i][\"layers\"]\n",
    "                print(layers)\n",
    "                layers = [int(a) for a in layers]\n",
    "                \n",
    "                #If layer nummber is mentioned instead of its position relative to the the current layer\n",
    "                if (layers[0]) > 0:\n",
    "                    layers[0] = layers[0] - i\n",
    "\n",
    "                if len(layers) == 1:\n",
    "                    x = layerOutputs[i + (layers[0])]\n",
    "\n",
    "                else:\n",
    "                    #If layer nummber is mentioned instead of its position relative to the the current layer\n",
    "                    if (layers[1]) > 0:\n",
    "                        layers[1] = layers[1] - i\n",
    "                    \n",
    "                    map1 = layerOutputs[i + layers[0]]\n",
    "                    map2 = layerOutputs[i + layers[1]]\n",
    "                    print(map1)\n",
    "                    print()\n",
    "                    print(map2)\n",
    "                    \n",
    "                    x = torch.cat((map1, map2), 1)\n",
    "                layerOutputs[i] = x\n",
    "            \n",
    "            #ShortCut is essentially residue from resnets\n",
    "            elif  module_type == \"shortcut\":\n",
    "                from_ = int(modules[i][\"from\"])\n",
    "                x = layerOutputs[i-1] + layerOutputs[i+from_]\n",
    "                layerOutputs[i] = x\n",
    "                \n",
    "            \n",
    "            \n",
    "            elif module_type == 'yolo':        \n",
    "                \n",
    "                anchors = self.moduleList[i][0].anchors\n",
    "                #Get the input dimensions\n",
    "                inp_dim = int (self.DNInfo[\"height\"])\n",
    "                \n",
    "                #Get the number of classes\n",
    "                num_classes = int (modules[i][\"classes\"])\n",
    "                \n",
    "                #Output the result\n",
    "                x = x.data\n",
    "                print(\"Size before transform => \" ,x.size())\n",
    "                \n",
    "                #Convert the output to 2D (batch x grids x bounding box attributes)\n",
    "                x = transformOutput(x, inp_dim, anchors, num_classes, CUDA)\n",
    "                print(\"Size after transform => \" ,x.size())\n",
    "\n",
    "                \n",
    "                #If no detections were made\n",
    "                if type(x) == int:\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                if not written_output:\n",
    "                    detections = x\n",
    "                    written_output = 1\n",
    "                \n",
    "                else:\n",
    "                    detections = torch.cat((detections, x), 1)\n",
    "                \n",
    "                layerOutputs[i] = layerOutputs[i-1]\n",
    "                \n",
    "        \n",
    "        try:\n",
    "            return detections\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "            \n",
    "    def load_weights(self, weightfile):\n",
    "        \n",
    "        fp = open(weightfile, \"rb\")\n",
    "\n",
    "        #The first 4 values are header information \n",
    "        # 1. Major version number\n",
    "        # 2. Minor Version Number\n",
    "        # 3. Subversion number \n",
    "        # 4. IMages seen \n",
    "        header = np.fromfile(fp, dtype = np.int32, count = 5)\n",
    "        self.header = torch.from_numpy(header)\n",
    "        self.seen = self.header[3]\n",
    "        \n",
    "\n",
    "        weights = np.fromfile(fp, dtype = np.float32)\n",
    "        \n",
    "        tracker = 0\n",
    "        for i in range(len(self.moduleList)):\n",
    "            module_type = self.netBlocks[i + 1][\"type\"]\n",
    "            \n",
    "            if module_type == \"convolutional\":\n",
    "                model = self.moduleList[i]\n",
    "                try:\n",
    "                    batch_normalize = int(self.netBlocks[i+1][\"batch_normalize\"])\n",
    "                except:\n",
    "                    batch_normalize = 0\n",
    "                \n",
    "                convPart = model[0]\n",
    "                \n",
    "                if (batch_normalize):\n",
    "                    #Weights file Configuration=> bn bais->bn weights-> running mean-> running var\n",
    "                    #The weights are arranged in the above mentioned order\n",
    "                    bnPart = model[1]\n",
    "                    \n",
    "                    biasCount = bnPart.bias.numel()\n",
    "                    \n",
    "                    bnBias = torch.from_numpy(weights[tracker:tracker + biasCount])\n",
    "                    tracker += biasCount\n",
    "                    \n",
    "                    bnPart_weights = torch.from_numpy(weights[tracker: tracker + biasCount])\n",
    "                    tracker  += biasCount\n",
    "                    \n",
    "                    bnPart_running_mean = torch.from_numpy(weights[tracker: tracker + biasCount])\n",
    "                    tracker  += biasCount\n",
    "                    \n",
    "                    bnPart_running_var = torch.from_numpy(weights[tracker: tracker + biasCount])\n",
    "                    tracker  += biasCount\n",
    "                    \n",
    "                    bnBias = bnBias.view_as(bnPart.bias.data)\n",
    "                    bnPart_weights = bnPart_weights.view_as(bnPart.weight.data)\n",
    "                    bnPart_running_mean = bnPart_running_mean.view_as(bnPart.running_mean)\n",
    "                    bnPart_running_var = bnPart_running_var.view_as(bnPart.running_var)\n",
    "\n",
    "                    bnPart.bias.data.copy_(bnBias)\n",
    "                    bnPart.weight.data.copy_(bnPart_weights)\n",
    "                    bnPart.running_mean.copy_(bnPart_running_mean)\n",
    "                    bnPart.running_var.copy_(bnPart_running_var)\n",
    "                \n",
    "                else:\n",
    "                    biasCount = convPart.bias.numel()\n",
    "                \n",
    "                    convBias = torch.from_numpy(weights[tracker: tracker + biasCount])\n",
    "                    tracker = tracker + biasCount\n",
    "                    \n",
    "                    convBias = convBias.view_as(convPart.bias.data)\n",
    "                    \n",
    "                    convPart.bias.data.copy_(convBias)\n",
    "                    \n",
    "                    \n",
    "                weightfile = convPart.weight.numel()\n",
    "                \n",
    "                convWeight = torch.from_numpy(weights[tracker:tracker+weightfile])\n",
    "                tracker = tracker + weightfile\n",
    "\n",
    "                convWeight = convWeight.view_as(convPart.weight.data)\n",
    "                convPart.weight.data.copy_(convWeight)\n",
    "'''\n",
    "#Test CFG:\n",
    "construct = construct_cfg('cfg/yolov3.cfg')\n",
    "print(construct,\"/n constructed from cfg file\")\n",
    "'''\n",
    "\n",
    "#TestMOdel:\n",
    "\n",
    "num_classes = 80\n",
    "classes = load_classes('data/coco.names') \n",
    "\n",
    "model = net('C:/Users/User/Yolov4/cfg/yolov3.cfg')\n",
    "model.load_weights(\"C:/Users/User/Yolov4/weights/yolov3.weights\")\n",
    "print(\"Network loaded\")\n",
    "\n",
    "test_data = torch.randn(1,3,256,256,dtype = torch.float)\n",
    "test_output = model(test_data,False)\n",
    "\n",
    "print(test_output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
