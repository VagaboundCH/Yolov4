{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import import_ipynb\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def count_learnable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def convert2cpu(matrix):\n",
    "    if matrix.is_cuda:\n",
    "        return torch.FloatTensor(matrix.size()).copy_(matrix)\n",
    "    else:\n",
    "        return matrix\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #Get the coordinates of bounding boxes\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]\n",
    "    \n",
    "    #get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 =  torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 =  torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 =  torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 =  torch.min(b1_y2, b2_y2)\n",
    "    \n",
    "    #Intersection area\n",
    "    if torch.cuda.is_available():\n",
    "            inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1,torch.zeros(inter_rect_x2.shape).cuda())*torch.max(inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape).cuda())\n",
    "    else:\n",
    "            inter_area = torch.max(inter_rect_x2 - inter_rect_x1 + 1,torch.zeros(inter_rect_x2.shape))*torch.max(inter_rect_y2 - inter_rect_y1 + 1, torch.zeros(inter_rect_x2.shape))\n",
    "    \n",
    "    #Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n",
    "    \n",
    "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "\n",
    "def transformOutput(prediction, inp_dim, anchors, num_classes, CUDA = True):\n",
    "    batch_size = prediction.size(0)\n",
    "    stride =  inp_dim // prediction.size(2)\n",
    "    grid_size = inp_dim // stride\n",
    "    bbox_attrs = 5 + num_classes\n",
    "    num_anchors = len(anchors)\n",
    "    \n",
    "    anchors = [(a[0]/stride, a[1]/stride) for a in anchors]\n",
    "\n",
    "\n",
    "\n",
    "    prediction = prediction.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)\n",
    "    prediction = prediction.transpose(1,2).contiguous()\n",
    "    prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)\n",
    "\n",
    "\n",
    "    #Sigmoid the  centre_X, centre_Y. and object confidencce\n",
    "    prediction[:,:,0] = torch.sigmoid(prediction[:,:,0])\n",
    "    prediction[:,:,1] = torch.sigmoid(prediction[:,:,1])\n",
    "    prediction[:,:,4] = torch.sigmoid(prediction[:,:,4])\n",
    "    \n",
    "\n",
    "    \n",
    "    #Add the center offsets\n",
    "    grid_len = np.arange(grid_size)\n",
    "    a,b = np.meshgrid(grid_len, grid_len)\n",
    "    \n",
    "    x_offset = torch.FloatTensor(a).view(-1,1)\n",
    "    y_offset = torch.FloatTensor(b).view(-1,1)\n",
    "    \n",
    "    if CUDA:\n",
    "        x_offset = x_offset.cuda()\n",
    "        y_offset = y_offset.cuda()\n",
    "    \n",
    "    x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1,num_anchors).view(-1,2).unsqueeze(0)\n",
    "    \n",
    "    prediction[:,:,:2] += x_y_offset\n",
    "      \n",
    "    anchors = torch.FloatTensor(anchors)\n",
    "    \n",
    "    if CUDA:\n",
    "        anchors = anchors.cuda()\n",
    "        \n",
    "    #Transform the anchors using log opearation given in research paper\n",
    "    anchors = anchors.repeat(grid_size*grid_size, 1).unsqueeze(0)\n",
    "    prediction[:,:,2:4] = torch.exp(prediction[:,:,2:4])*anchors\n",
    "\n",
    "    #Softmax the class scores\n",
    "    prediction[:,:,5: 5 + num_classes] = torch.sigmoid((prediction[:,:, 5 : 5 + num_classes]))\n",
    "\n",
    "    prediction[:,:,:4] *= stride\n",
    "   \n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def load_classes(namesfile):\n",
    "    with open(namesfile, \"r\") as fp:\n",
    "#     names = fp.read().split(\"\\n\")[:-1]\n",
    "### https://github.com/ayooshkathuria/pytorch-yolo-v3/issues/118 ###\n",
    "        names = [i.strip('\\n') for i in fp.readlines()]\n",
    "    return names\n",
    "\n",
    "def get_im_dim(im):\n",
    "    im = cv2.imread(im)\n",
    "    w,h = im.shape[1], im.shape[0]\n",
    "    return w,h\n",
    "\n",
    "def unique(tensor):\n",
    "    tensor_np = tensor.cpu().numpy()\n",
    "    unique_np = np.unique(tensor_np)\n",
    "    unique_tensor = torch.from_numpy(unique_np)\n",
    "    \n",
    "    tensor_res = tensor.new(unique_tensor.shape)\n",
    "    tensor_res.copy_(unique_tensor)\n",
    "    return tensor_res\n",
    "\n",
    "def write_results(prediction, confidence, num_classes, nms = True, nms_conf = 0.4):\n",
    "    conf_mask = (prediction[:,:,4] > confidence).float().unsqueeze(2)\n",
    "    prediction = prediction*conf_mask\n",
    "    \n",
    "\n",
    "    try:\n",
    "        ind_nz = torch.nonzero(prediction[:,:,4]).transpose(0,1).contiguous()\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    box_a = prediction.new(prediction.shape)\n",
    "    box_a[:,:,0] = (prediction[:,:,0] - prediction[:,:,2]/2)\n",
    "    box_a[:,:,1] = (prediction[:,:,1] - prediction[:,:,3]/2)\n",
    "    box_a[:,:,2] = (prediction[:,:,0] + prediction[:,:,2]/2) \n",
    "    box_a[:,:,3] = (prediction[:,:,1] + prediction[:,:,3]/2)\n",
    "    prediction[:,:,:4] = box_a[:,:,:4]\n",
    "    \n",
    "\n",
    "    \n",
    "    batch_size = prediction.size(0)\n",
    "    \n",
    "\n",
    "    output = prediction.new(1, prediction.size(2) + 1)\n",
    "    write = False\n",
    "\n",
    "\n",
    "    for ind in range(batch_size):\n",
    "        #select the image from the batch\n",
    "        image_pred = prediction[ind]\n",
    "        \n",
    "\n",
    "        \n",
    "        #Get the class having maximum score, and the index of that class\n",
    "        #Get rid of num_classes softmax scores \n",
    "        #Add the class index and the class score of class having maximum score\n",
    "        max_conf, max_conf_score = torch.max(image_pred[:,5:5+ num_classes], 1)\n",
    "#         print('max_conf: ', len(max_conf))\n",
    "#         print('max_conf_score: ', len(max_conf_score.size())\n",
    "        max_conf = max_conf.float().unsqueeze(1)\n",
    "        print(max_conf.size())\n",
    "        max_conf_score = max_conf_score.float().unsqueeze(1)\n",
    "        seq = (image_pred[:,:5], max_conf, max_conf_score)\n",
    "        print('image_pred: ',image_pred.size())\n",
    "        print('max_conf: ',max_conf.size())\n",
    "        print('max_conf_score: ', max_conf_score.size())\n",
    "        image_pred = torch.cat(seq, 1)\n",
    "        print('image_pred: ', image_pred.size())\n",
    "        \n",
    "\n",
    "        \n",
    "        #Get rid of the zero entries\n",
    "        non_zero_ind =  (torch.nonzero(image_pred[:,4]))\n",
    "\n",
    "        \n",
    "        image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(-1,7)\n",
    "        \n",
    "        #Get the various classes detected in the image\n",
    "        try:\n",
    "            img_classes = unique(image_pred_[:,-1])\n",
    "        except:\n",
    "             continue\n",
    "        #WE will do NMS classwise\n",
    "        for cls in img_classes:\n",
    "            #get the detections with one particular class\n",
    "            cls_mask = image_pred_*(image_pred_[:,-1] == cls).float().unsqueeze(1)\n",
    "            class_mask_ind = torch.nonzero(cls_mask[:,-2]).squeeze()\n",
    "            \n",
    "\n",
    "            image_pred_class = image_pred_[class_mask_ind].view(-1,7)\n",
    "\n",
    "        \n",
    "             #sort the detections such that the entry with the maximum objectness\n",
    "             #confidence is at the top\n",
    "            conf_sort_index = torch.sort(image_pred_class[:,4], descending = True)[1]\n",
    "            image_pred_class = image_pred_class[conf_sort_index]\n",
    "            idx = image_pred_class.size(0)\n",
    "            \n",
    "            #if nms has to be done\n",
    "            if nms:\n",
    "                #For each detection\n",
    "                for i in range(idx):\n",
    "                    #Get the IOUs of all boxes that come after the one we are looking at \n",
    "                    #in the loop\n",
    "                    try:\n",
    "                        ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])\n",
    "                    except ValueError:\n",
    "                        break\n",
    "        \n",
    "                    except IndexError:\n",
    "                        break\n",
    "                    \n",
    "                    #Zero out all the detections that have IoU > treshhold\n",
    "                    iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
    "                    image_pred_class[i+1:] *= iou_mask       \n",
    "                    \n",
    "                    #Remove the non-zero entries\n",
    "                    non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()\n",
    "                    image_pred_class = image_pred_class[non_zero_ind].view(-1,7)\n",
    "                    \n",
    "                    \n",
    "\n",
    "            #Concatenate the batch_id of the image to the detection\n",
    "            #this helps us identify which image does the detection correspond to \n",
    "            #We use a linear straucture to hold ALL the detections from the batch\n",
    "            #the batch_dim is flattened\n",
    "            #batch is identified by extra batch column\n",
    "            \n",
    "            \n",
    "            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)\n",
    "            seq = batch_ind, image_pred_class\n",
    "            if not write:\n",
    "                output = torch.cat(seq,1)\n",
    "                write = True\n",
    "            else:\n",
    "                out = torch.cat(seq,1)\n",
    "                output = torch.cat((output,out))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([1, 2, 4])\n",
      "torch.Size([2, 1, 4])\n",
      "torch.Size([2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4],[5,6,7,8]])\n",
    "print(x.size())\n",
    "a0 = torch.unsqueeze(x, 0)\n",
    "a1 = torch.unsqueeze(x, 1)\n",
    "a2 = torch.unsqueeze(x, 2)\n",
    "print(a0.size())\n",
    "print(a1.size())\n",
    "print(a2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
